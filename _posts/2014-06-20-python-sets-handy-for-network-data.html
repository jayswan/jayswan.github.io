---
layout: post
title: 'Python Sets: Handy for Network Data'
date: '2014-06-20T10:55:00.001-06:00'
author: Jay Swan
tags: 
modified_time: '2014-06-20T10:55:02.147-06:00'
blogger_id: tag:blogger.com,1999:blog-5029689981158113588.post-5751517142699265196
blogger_orig_url: http://unroutable.blogspot.com/2014/06/python-sets-handy-for-network-data.html
---

My Python-related posts seem to get the most reads, so here's another one!<br /><br />A problem that comes up fairly often in networking is finding the number of occurrences of unique items in a large collection of data: let's say you want to find all of the unique IP addresses that accessed a website, traversed a firewall, got denied by an ACL, or whatever. Maybe you've extracted the following list from a log file:<br /><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">1.1.1.1</span></span><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">2.2.2.2</span></span><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">3.3.3.3</span></span><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">1.1.1.1</span></span><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">5.5.5.5</span></span><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">5.5.5.5</span></span><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">1.1.1.1</span></span><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">2.2.2.2 </span></span><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">...</span></span><br /><br />and you need to reduce this to:<br /><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">1.1.1.1</span></span><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">2.2.2.2</span></span><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">3.3.3.3</span></span><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">5.5.5.5</span></span><br /><br />In other words, we're removing the duplicates. In low-level programming languages, removing duplicates is a bit of a pain: generally you need to implement an efficient way to sort an array of items, then traverse the sorted array to check for adjacent duplicates and remove them. In a language that has dictionaries (also known as hash tables or associative arrays), you can do it by adding each item as a key in your dictionary with an empty value, then extract the keys. In Python:<br /><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">&gt;&gt;&gt; items = ['1.1.1.1','2.2.2.2','3.3.3.3','1.1.1.1','5.5.5.5','5.5.5.5','1.1.1.1','2.2.2.2']<br />&gt;&gt;&gt; d = {}<br />&gt;&gt;&gt; for item in items:<br />...&nbsp;&nbsp;&nbsp;&nbsp; d[item] = None<br />...<br />&gt;&gt;&gt; d<br />{'5.5.5.5': None, '3.3.3.3': None, '1.1.1.1': None, '2.2.2.2': None}<br />&gt;&gt;&gt; unique = d.keys()<br />&gt;&gt;&gt; unique<br />['5.5.5.5', '3.3.3.3', '1.1.1.1', '2.2.2.2']</span></span><br /><br />or, more concisely using a dictionary comprehension:<br /><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">&gt;&gt;&gt; {item:None for item in items}.keys()<br />['5.5.5.5', '3.3.3.3', '1.1.1.1', '2.2.2.2']</span></span><br /><br />Python has an even better way, however: the "set" type, which emulates the mathematical idea of a set as a collection of distinct items. If you create an empty set and add items to it, duplicates will automatically be thrown away:<br /><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">&gt;&gt;&gt; s = set()<br />&gt;&gt;&gt; s.add('1.1.1.1')<br />&gt;&gt;&gt; s<br />set(['1.1.1.1'])<br />&gt;&gt;&gt; s.add('2.2.2.2')<br />&gt;&gt;&gt; s.add('1.1.1.1')<br />&gt;&gt;&gt; s<br />set(['1.1.1.1', '2.2.2.2'])<br />&gt;&gt;&gt; for item in items:<br />...&nbsp;&nbsp;&nbsp;&nbsp; s.add(item)<br />...<br />&gt;&gt;&gt; s<br />set(['5.5.5.5', '3.3.3.3', '1.1.1.1', '2.2.2.2'])</span></span><br /><br />Predictably, you can use set comprehensions just like list comprehensions to do the same thing as a one liner:<br /><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">&gt;&gt;&gt; {item for item in items}<br />set(['5.5.5.5', '3.3.3.3', '1.1.1.1', '2.2.2.2'])</span></span><br /><br />Or, if you have a list built already you can just convert it to a set:<br /><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">&gt;&gt;&gt; set(items)<br />set(['5.5.5.5', '3.3.3.3', '1.1.1.1', '2.2.2.2'])</span></span><br /><br />Python also provides methods for the most common types of set operations: union, intersection, difference and symmetric difference. Because these methods accept lists or other iterables, you can quickly find similarities between collections of items:<br /><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">&gt;&gt;&gt; items<br />['1.1.1.1', '2.2.2.2', '3.3.3.3', '1.1.1.1', '5.5.5.5', '5.5.5.5', '1.1.1.1', '2.2.2.2']<br />&gt;&gt;&gt; more_items = ['1.1.1.1','8.8.8.8','1.1.1.1','7.7.7.7','2.2.2.2']<br />&gt;&gt;&gt; set(items).intersection(more_items)<br />set(['1.1.1.1', '2.2.2.2'])</span></span><br /><span style="font-size: small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">&gt;&gt;&gt; set(items).difference(more_items)<br />set(['5.5.5.5', '3.3.3.3'])</span></span><br /><br />Have fun!<br /><br />